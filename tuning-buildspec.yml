version: 0.2

phases:
  install:
    runtime-versions:
      python: 3.8
    commands:
      - echo Installing dependencies
      - pip install --upgrade pip
      - pip install awscli boto3 sagemaker
  
  pre_build:
    commands:
      # Setup environment variables
      - ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
      - PROJECT_NAME=$(cat cloudformation.yaml | grep -m 1 'ProjectName' -A 3 | grep 'Default:' | awk '{print $2}')
      - ENVIRONMENT=$(cat cloudformation.yaml | grep -m 1 'EnvironmentName' -A 3 | grep 'Default:' | awk '{print $2}')
      
      # Get bucket information
      - S3_BUCKET="${PROJECT_NAME}-${ENVIRONMENT}-artifacts-${ACCOUNT_ID}"
      - S3_DATA_PREFIX="mscoco_processed"
      
      # Check if hyperparameter tuning should be run
      - |
        RUN_HPO=$(aws ssm get-parameter --name "/${PROJECT_NAME}/${ENVIRONMENT}/run-hpo" --query "Parameter.Value" --output text || echo "false")
        echo "Run hyperparameter tuning: $RUN_HPO"
      
      # Get image URIs from previous stage
      - |
        if [ -f ../BuildOutput/build_output.json ]; then
          TRAINING_IMAGE_URI=$(cat ../BuildOutput/build_output.json | jq -r '.TrainingImageUri')
          INFERENCE_IMAGE_URI=$(cat ../BuildOutput/build_output.json | jq -r '.InferenceImageUri')
          echo "Training image: $TRAINING_IMAGE_URI"
          echo "Inference image: $INFERENCE_IMAGE_URI"
        else
          echo "Could not find build output. Using default image URIs."
          TRAINING_IMAGE_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${PROJECT_NAME}-${ENVIRONMENT}-repository:latest-training"
          INFERENCE_IMAGE_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${PROJECT_NAME}-${ENVIRONMENT}-repository:latest-inference"
        fi
  
  build:
    commands:
      # Check if training data exists in S3
      - |
        if [ "$RUN_HPO" = "true" ]; then
          echo "Checking if training data exists in S3..."
          if aws s3 ls s3://${S3_BUCKET}/${S3_DATA_PREFIX}/ | grep -q ".npy"; then
            echo "Starting SageMaker hyperparameter tuning job..."
            
            # Generate job name with timestamp
            TIMESTAMP=$(date +%Y%m%d%H%M%S)
            HPO_JOB_NAME="${PROJECT_NAME}-${ENVIRONMENT}-hpo-${TIMESTAMP}"
            
            # Get SageMaker role ARN
            SAGEMAKER_ROLE_ARN=$(aws cloudformation describe-stacks --stack-name STACKMOEGAN --query "Stacks[0].Outputs[?OutputKey=='SageMakerRoleArn'].OutputValue" --output text || echo "arn:aws:iam::${ACCOUNT_ID}:role/${PROJECT_NAME}-${ENVIRONMENT}-sagemaker-role")
            
            # Start hyperparameter tuning job
            python scripts/hyperparameter_tuning.py \
              --job-name $HPO_JOB_NAME \
              --role-arn $SAGEMAKER_ROLE_ARN \
              --image-uri $TRAINING_IMAGE_URI \
              --bucket $S3_BUCKET \
              --prefix tuning/$HPO_JOB_NAME \
              --data-bucket $S3_BUCKET \
              --data-prefix $S3_DATA_PREFIX \
              --instance-type ml.g4dn.xlarge \
              --max-jobs 5 \
              --max-parallel-jobs 2 \
              --config configs/hyperparameter_config.json
              
            echo "Hyperparameter tuning job started: $HPO_JOB_NAME"
            
            # Create a CloudWatch event to track when the best tuning job completes
            # This could trigger another build stage to deploy the best model
            
            # Reset the SSM parameter to avoid running HPO again automatically
            aws ssm put-parameter --name "/${PROJECT_NAME}/${ENVIRONMENT}/run-hpo" --type "String" --value "false" --overwrite
            
          else
            echo "No training data found in S3. Cannot start hyperparameter tuning job."
          fi
        else
          echo "Hyperparameter tuning skipped as indicated by SSM parameter"
        fi
  
  post_build:
    commands:
      # Create output file
      - |
        cat > tuning_output.json << EOF
        {
          "TuningInitiated": "$([[ "$RUN_HPO" = "true" ]] && echo "true" || echo "false")",
          "S3Bucket":"$S3_BUCKET",
          "S3DataPrefix":"$S3_DATA_PREFIX"
        }
        EOF
      - echo "Hyperparameter tuning stage complete."

artifacts:
  files:
    - tuning_output.json
  discard-paths: yes