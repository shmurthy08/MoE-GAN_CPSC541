AWSTemplateFormatVersion: '2010-09-09'
Description: 'Infrastructure for Text-to-Image GAN Model with SageMaker and API Gateway'

Parameters:
  ProjectName:
    Type: String
    Default: gan-text-to-image
    Description: Name of the project for resource naming
  
  EnvironmentName:
    Type: String
    Default: dev
    AllowedValues: [dev, test, prod]
    Description: Environment name
  
  ModelArtifactUrl:
    Type: String
    Default: ''
    Description: S3 URL of the model artifact (optional for initial setup)
  
  ContainerImage:
    Type: String
    Default: ''
    Description: ECR image URL for the model container (optional for initial setup)
  
  InstanceType:
    Type: String
    Default: ml.t2.medium
    AllowedValues:
      - ml.m5.xlarge
      - ml.t2.medium
      - ml.g5.xlarge
      - ml.g5.2xlarge
      - ml.g6.xlarge
      - ml.g6.2xlarge
    Description: SageMaker instance type for the endpoint (free tier eligible)

Resources:
  # ===== IAM Roles =====
  SageMakerRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: sagemaker.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AdministratorAccess
      RoleName: !Sub '${ProjectName}-${EnvironmentName}-sagemaker-role'

  LambdaRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AdministratorAccess
      RoleName: !Sub '${ProjectName}-${EnvironmentName}-lambda-role'

  # ===== Storage Resources =====
  ModelArtifactBucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Sub '${ProjectName}-${EnvironmentName}-artifacts-${AWS::AccountId}'
      VersioningConfiguration:
        Status: Enabled

  # ===== DynamoDB Table for Job Status =====
  GenerationJobsTable:
    Type: 'AWS::DynamoDB::Table'
    Properties:
      TableName: !Sub '${ProjectName}-${EnvironmentName}-generation-jobs'
      AttributeDefinitions:
        - AttributeName: request_id
          AttributeType: S
      KeySchema:
        - AttributeName: request_id
          KeyType: HASH
      BillingMode: PAY_PER_REQUEST  # Free tier eligible
      TimeToLiveSpecification:
        AttributeName: expiration_time
        Enabled: true

  # ===== SageMaker Resources =====
  SageMakerModel:
    Type: 'AWS::SageMaker::Model'
    Condition: HasModelArtifact
    Properties:
      ExecutionRoleArn: !GetAtt SageMakerRole.Arn
      ModelName: !Sub '${ProjectName}-${EnvironmentName}-model'
      PrimaryContainer:
        Image: !Ref ContainerImage
        ModelDataUrl: !Ref ModelArtifactUrl

  SageMakerEndpointConfig:
    Type: 'AWS::SageMaker::EndpointConfig'
    Condition: HasModelArtifact
    Properties:
      EndpointConfigName: !Sub '${ProjectName}-${EnvironmentName}-endpoint-config'
      ProductionVariants:
        - InitialInstanceCount: 1
          InstanceType: !Ref InstanceType
          ModelName: !GetAtt SageMakerModel.ModelName
          VariantName: 'AllTraffic'
          InitialVariantWeight: 1.0

  SageMakerEndpoint:
    Type: 'AWS::SageMaker::Endpoint'
    Condition: HasModelArtifact
    Properties:
      EndpointName: !Sub '${ProjectName}-${EnvironmentName}-endpoint'
      EndpointConfigName: !GetAtt SageMakerEndpointConfig.EndpointConfigName

  # ===== Lambda Functions =====
  InferenceLambda:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: !Sub '${ProjectName}-${EnvironmentName}-inference'
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.handler
      Timeout: 500
      MemorySize: 256
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import uuid
          import time
          import logging
          from datetime import datetime, timedelta

          # Configure logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          # Updated InferenceLambda with consistent ID handling and verified S3 upload
          def handler(event, context):
              # Log the incoming request
              logger.info(f"InferenceLambda received request: {json.dumps(event, default=str)}")
              
              # Hardcode endpoint name and DynamoDB table name as requested
              endpoint_name = 'gan-ep-dev'
              dynamodb_table = 'gan-text-to-image-dev-generation-jobs'
              s3_bucket_name = 'gan-text-to-image-dev-artifacts-207567761455'
              
              # Handle OPTIONS request for CORS
              if event.get('httpMethod') == 'OPTIONS':
                  logger.info("Handling OPTIONS request for CORS")
                  return {
                      'statusCode': 200,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                      },
                      'body': json.dumps({})
                  }
              
              # Get the text prompt from the request
              try:
                  body = json.loads(event.get('body', '{}'))
                  text_prompt = body.get('text', '')
                  logger.info(f"Received text prompt: {text_prompt}")
                  
                  if not text_prompt:
                      logger.warning("No text prompt provided in request")
                      return {
                          'statusCode': 400,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                          },
                          'body': json.dumps({
                              'error': 'Text prompt is required in the request body.'
                          })
                      }
                  
                  # Generate a unique request ID - IMPORTANT: Use a short, simple format for easier debugging
                  # Use time-based component to make it easier to track in logs
                  timestamp = int(time.time())
                  request_id = f"req-{timestamp}-{uuid.uuid4().hex[:8]}"
                  logger.info(f"Generated request_id: {request_id}")
                  
                  # Prepare the request payload
                  request_payload = json.dumps({
                      'text': text_prompt,
                      'request_id': request_id  # Include the request_id in the payload for traceability
                  })
                  
                  # Save the request to DynamoDB first with an INITIALIZING status
                  dynamodb = boto3.resource('dynamodb')
                  table = dynamodb.Table(dynamodb_table)
                  
                  # Calculate expiration time (24 hours from now)
                  expiration_time = int((datetime.now() + timedelta(hours=24)).timestamp())
                  
                  # Store initial job information
                  logger.info(f"Storing initial job information in DynamoDB: {dynamodb_table}")
                  table.put_item(
                      Item={
                          'request_id': request_id,
                          'status': 'INITIALIZING',
                          'prompt': text_prompt,
                          'created_at': timestamp,
                          'expiration_time': expiration_time
                      }
                  )
                  
                  # Create S3 path - use a consistent format
                  input_key = f"async-inputs/{request_id}.json"
                  s3_input_path = f"s3://{s3_bucket_name}/{input_key}"
                  logger.info(f"S3 input path: {s3_input_path}")
                  
                  # Upload to S3 with explicit verification
                  s3_client = boto3.client('s3')
                  logger.info(f"Uploading request payload to S3: {s3_input_path}")
                  
                  # Try to upload to S3
                  try:
                      s3_client.put_object(
                          Bucket=s3_bucket_name,
                          Key=input_key,
                          Body=request_payload,
                          ContentType='application/json'
                      )
                      
                      # Verify the file is actually there (important for debugging)
                      try:
                          s3_client.head_object(
                              Bucket=s3_bucket_name,
                              Key=input_key
                          )
                          logger.info(f"Successfully verified S3 upload at: {s3_input_path}")
                          
                          # Update DynamoDB with S3 path now that we've confirmed upload
                          table.update_item(
                              Key={'request_id': request_id},
                              UpdateExpression='SET #status = :status, #s3_path = :s3_path',
                              ExpressionAttributeNames={
                                  '#status': 'status',
                                  '#s3_path': 's3_input_path'
                              },
                              ExpressionAttributeValues={
                                  ':status': 'UPLOADED',
                                  ':s3_path': s3_input_path
                              }
                          )
                      except Exception as verify_error:
                          logger.error(f"Failed to verify S3 upload: {str(verify_error)}")
                          raise Exception(f"Upload verification failed: {str(verify_error)}")
                          
                  except Exception as s3_error:
                      logger.error(f"Failed to upload to S3: {str(s3_error)}")
                      
                      # Update DynamoDB with error
                      table.update_item(
                          Key={'request_id': request_id},
                          UpdateExpression='SET #status = :status, #error = :error',
                          ExpressionAttributeNames={
                              '#status': 'status',
                              '#error': 'error'
                          },
                          ExpressionAttributeValues={
                              ':status': 'FAILED',
                              ':error': f"S3 upload failed: {str(s3_error)}"
                          }
                      )
                      
                      return {
                          'statusCode': 500,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                          },
                          'body': json.dumps({
                              'request_id': request_id,
                              'status': 'FAILED',
                              'error': f"Failed to upload input to S3: {str(s3_error)}"
                          })
                      }
                  
                  # Check if endpoint exists before invoking
                  sagemaker = boto3.client('sagemaker')
                  endpoint_exists = True
                  
                  try:
                      sagemaker.describe_endpoint(EndpointName=endpoint_name)
                      logger.info(f"Endpoint {endpoint_name} exists")
                  except Exception as endpoint_error:
                      logger.warning(f"Endpoint doesn't exist or other error: {str(endpoint_error)}")
                      endpoint_exists = False
                      
                      # Update DynamoDB to indicate no endpoint
                      table.update_item(
                          Key={'request_id': request_id},
                          UpdateExpression='SET #status = :status, #message = :message',
                          ExpressionAttributeNames={
                              '#status': 'status',
                              '#message': 'message'
                          },
                          ExpressionAttributeValues={
                              ':status': 'NO_ENDPOINT',
                              ':message': f"Endpoint {endpoint_name} not available"
                          }
                      )
                      
                      # Return success response with explanation
                      return {
                          'statusCode': 200,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                          },
                          'body': json.dumps({
                              'request_id': request_id,
                              'status': 'READY_FOR_PROCESSING',
                              'message': 'Input saved but endpoint not available. Will process when endpoint is ready.'
                          })
                      }
                  
                  # Only try to invoke endpoint if it exists
                  if endpoint_exists:
                      try:
                          # Create the SageMaker async request
                          logger.info(f"Submitting async request to SageMaker endpoint: {endpoint_name}")
                          sagemaker_runtime = boto3.client('sagemaker-runtime')
                          
                          async_response = sagemaker_runtime.invoke_endpoint_async(
                              EndpointName=endpoint_name,
                              ContentType='application/json',
                              Accept='application/json',
                              InputLocation=s3_input_path
                          )
                          
                          # Get the SageMaker inference ID
                          inference_id = async_response.get('InferenceId')
                          logger.info(f"Received SageMaker InferenceId: {inference_id}")
                          
                          # Update DynamoDB with the SageMaker inference ID
                          table.update_item(
                              Key={'request_id': request_id},
                              UpdateExpression='SET #status = :status, #inference_id = :inference_id',
                              ExpressionAttributeNames={
                                  '#status': 'status',
                                  '#inference_id': 'sagemaker_inference_id'
                              },
                              ExpressionAttributeValues={
                                  ':status': 'IN_PROGRESS',
                                  ':inference_id': inference_id
                              }
                          )
                          
                          # Start a separate Lambda to check status
                          processor_lambda = os.environ.get('PROCESSOR_LAMBDA', '')
                          logger.info(f"Invoking ProcessorLambda ({processor_lambda}) asynchronously")
                          lambda_client = boto3.client('lambda')
                          lambda_client.invoke(
                              FunctionName=processor_lambda,
                              InvocationType='Event',  # Asynchronous invocation
                              Payload=json.dumps({
                                  'request_id': request_id,
                                  'inference_id': inference_id,
                                  'endpoint_name': endpoint_name,
                                  's3_input_path': s3_input_path
                              })
                          )
                      except Exception as invoke_error:
                          logger.error(f"Error invoking SageMaker endpoint: {str(invoke_error)}")
                          
                          # Update DynamoDB with error
                          table.update_item(
                              Key={'request_id': request_id},
                              UpdateExpression='SET #status = :status, #error = :error',
                              ExpressionAttributeNames={
                                  '#status': 'status',
                                  '#error': 'error'
                              },
                              ExpressionAttributeValues={
                                  ':status': 'INVOCATION_FAILED',
                                  ':error': f"SageMaker invocation failed: {str(invoke_error)}"
                              }
                          )
                          
                          return {
                              'statusCode': 500,
                              'headers': {
                                  'Content-Type': 'application/json',
                                  'Access-Control-Allow-Origin': '*',
                                  'Access-Control-Allow-Headers': 'Content-Type',
                                  'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                              },
                              'body': json.dumps({
                                  'request_id': request_id,
                                  'status': 'FAILED',
                                  'error': f"Failed to invoke SageMaker endpoint: {str(invoke_error)}"
                              })
                          }
                  
                  # Return success response to client
                  return {
                      'statusCode': 200,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                      },
                      'body': json.dumps({
                          'request_id': request_id,
                          'status': 'ACCEPTED',
                          'message': 'Request accepted. Poll for results using the request_id.'
                      })
                  }
              except Exception as e:
                  logger.error(f"Unhandled exception in handler: {str(e)}")
                  return {
                      'statusCode': 500,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                      },
                      'body': json.dumps({
                          'error': f"Internal server error: {str(e)}"
                      })
                  }
      Environment:
        Variables:
          SAGEMAKER_ENDPOINT_NAME: 'gan-ep-dev'  
          DYNAMODB_TABLE: 'gan-text-to-image-dev-generation-jobs'  
          PROCESSOR_LAMBDA: !GetAtt ProcessorLambda.Arn
          S3_BUCKET_NAME: !Ref ModelArtifactBucket  

  ProcessorLambda:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: !Sub '${ProjectName}-${EnvironmentName}-processor'
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.handler
      Timeout: 900  # Increased timeout for long-running tasks
      MemorySize: 512
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import time
          import logging

          # Configure logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def handler(event, context):
            # Log the incoming event
            logger.info(f"ProcessorLambda started with request_id: {event.get('request_id')}")
            
            # Get parameters from the event
            request_id = event.get('request_id')
            inference_id = event.get('inference_id')
            
            # Hardcode endpoint name and DynamoDB table name as requested
            endpoint_name = 'gan-ep-dev'
            dynamodb_table = 'gan-text-to-image-dev-generation-jobs'
            s3_bucket_name = 'gan-text-to-image-dev-artifacts-207567761455'
            
            # Initialize clients
            sagemaker_runtime = boto3.client('sagemaker-runtime')
            sagemaker = boto3.client('sagemaker')  # Regular SageMaker client, not runtime
            dynamodb = boto3.resource('dynamodb')
            table = dynamodb.Table(dynamodb_table)
            s3_client = boto3.client('s3')
            
            try:
                # Check the status of the SageMaker async inference job
                logger.info(f"Checking status of SageMaker async inference job: {inference_id}")
                             
                # Log the full response for debugging
                logger.info(f"SageMaker response: {json.dumps(response, default=str)}")
                
                # Check output S3 location directly
                output_prefix = f"async-outputs/{inference_id}"
                logger.info(f"Checking S3 for output at: {s3_bucket_name}/{output_prefix}")
                
                # List objects in the output prefix
                try:
                    s3_response = s3_client.list_objects_v2(
                        Bucket=s3_bucket_name,
                        Prefix=output_prefix,
                        MaxKeys=1
                    )
                    
                    # Check if any output file exists
                    if 'Contents' in s3_response and len(s3_response['Contents']) > 0:
                        # Output file exists, get the first one
                        output_key = s3_response['Contents'][0]['Key']
                        logger.info(f"Found output file: {output_key}")
                        
                        # Get the output file
                        object_response = s3_client.get_object(
                            Bucket=s3_bucket_name,
                            Key=output_key
                        )
                        
                        result_data = object_response['Body'].read().decode('utf-8')
                        result = json.loads(result_data)
                        
                        # Update DynamoDB with completed status
                        logger.info(f"Updating DynamoDB with COMPLETED status for request_id: {request_id}")
                        table.update_item(
                            Key={'request_id': request_id},
                            UpdateExpression='SET #status = :status, #data = :data, #updated_at = :updated_at',
                            ExpressionAttributeNames={
                                '#status': 'status',
                                '#data': 'data',
                                '#updated_at': 'updated_at'
                            },
                            ExpressionAttributeValues={
                                ':status': 'COMPLETED',
                                ':data': result,
                                ':updated_at': int(time.time())
                            }
                        )
                        
                        logger.info(f"ProcessorLambda completed successfully for request_id: {request_id}")
                        return {
                            'statusCode': 200,
                            'body': json.dumps({
                                'message': 'Processing completed successfully'
                            })
                        }
                    else:
                        # No output file yet, check for error file
                        error_prefix = f"async-outputs/{inference_id}/error"
                        s3_error_response = s3_client.list_objects_v2(
                            Bucket=s3_bucket_name,
                            Prefix=error_prefix,
                            MaxKeys=1
                        )
                        
                        if 'Contents' in s3_error_response and len(s3_error_response['Contents']) > 0:
                            # Error file exists, job failed
                            error_key = s3_error_response['Contents'][0]['Key']
                            logger.error(f"Found error file: {error_key}")
                            
                            # Get the error file
                            error_object = s3_client.get_object(
                                Bucket=s3_bucket_name,
                                Key=error_key
                            )
                            
                            error_data = error_object['Body'].read().decode('utf-8')
                            
                            # Update DynamoDB with failed status
                            table.update_item(
                                Key={'request_id': request_id},
                                UpdateExpression='SET #status = :status, #error = :error, #updated_at = :updated_at',
                                ExpressionAttributeNames={
                                    '#status': 'status',
                                    '#error': 'error',
                                    '#updated_at': 'updated_at'
                                },
                                ExpressionAttributeValues={
                                    ':status': 'FAILED',
                                    ':error': error_data,
                                    ':updated_at': int(time.time())
                                }
                            )
                            
                            return {
                                'statusCode': 200,
                                'body': json.dumps({
                                    'message': 'Processing failed'
                                })
                            }
                        else:
                            # No output or error file yet, job still in progress
                            # Update the last checked timestamp in DynamoDB
                            table.update_item(
                                Key={'request_id': request_id},
                                UpdateExpression='SET last_checked = :last_checked',
                                ExpressionAttributeValues={
                                    ':last_checked': int(time.time())
                                }
                            )
                            
                            # Wait before re-checking
                            time.sleep(5)
                            
                            # Re-invoke this Lambda to check status again
                            logger.info(f"Job still in progress. Re-invoking Lambda to check status later.")
                            lambda_client = boto3.client('lambda')
                            lambda_client.invoke(
                                FunctionName=context.function_name,
                                InvocationType='Event',  # Asynchronous invocation
                                Payload=json.dumps(event)
                            )
                            
                            return {
                                'statusCode': 200,
                                'body': json.dumps({
                                    'message': 'Processing still in progress'
                                })
                            }
                except Exception as s3_error:
                    logger.error(f"Error checking S3: {str(s3_error)}")
                    # Fall back to regular status check
            
            except Exception as e:
                logger.error(f"Error processing request {request_id}: {str(e)}")
                
                # Update the job status with the error
                table.update_item(
                    Key={'request_id': request_id},
                    UpdateExpression='SET #status = :status, #error = :error, #updated_at = :updated_at',
                    ExpressionAttributeNames={
                        '#status': 'status',
                        '#error': 'error',
                        '#updated_at': 'updated_at'
                    },
                    ExpressionAttributeValues={
                        ':status': 'FAILED',
                        ':error': str(e),
                        ':updated_at': int(time.time())
                    }
                )
                
                return {
                    'statusCode': 500,
                    'body': json.dumps({
                        'error': str(e)
                    })
                }

            # Final fallback - if we couldn't determine status, check again later
            lambda_client = boto3.client('lambda')
            lambda_client.invoke(
                FunctionName=context.function_name,
                InvocationType='Event',
                Payload=json.dumps(event)
            )
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'message': 'Status check in progress'
                })
            }
      Environment:
        Variables:
          DYNAMODB_TABLE: 'gan-text-to-image-dev-generation-jobs'  
          SAGEMAKER_ENDPOINT_NAME: 'gan-ep-dev'
  ImageMetricsLambda:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: !Sub '${ProjectName}-${EnvironmentName}-image-metrics'
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.handler
      Timeout: 600
      MemorySize: 512  # Reduced from 1024 to save costs
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import base64
          import uuid
          import time
          from datetime import datetime, timedelta
          
          def handler(event, context):
              # Get the endpoint name
              endpoint_name = os.environ.get('SAGEMAKER_ENDPOINT_NAME', '')
              if not endpoint_name:
                  endpoint_name = 'gan-ep-' + os.environ.get('ENVIRONMENT', 'dev')
              
              dynamodb_table = os.environ.get('DYNAMODB_TABLE', '')
              
              try:
                  body = json.loads(event.get('body', '{}'))
                  text_prompt = body.get('text', '')
                  num_samples = min(body.get('num_samples', 4), 8)
                  
                  if not text_prompt:
                      return {
                          'statusCode': 400,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                          },
                          'body': json.dumps({
                              'error': 'Text prompt is required'
                          })
                      }
                  
                  # Generate a unique request ID
                  request_id = str(uuid.uuid4())
                  
                  # Save the request to DynamoDB
                  dynamodb = boto3.resource('dynamodb')
                  table = dynamodb.Table(dynamodb_table)
                  
                  # Calculate expiration time (24 hours from now)
                  expiration_time = int((datetime.now() + timedelta(hours=24)).timestamp())
                  
                  # Store initial job information
                  table.put_item(
                      Item={
                          'request_id': request_id,
                          'status': 'IN_PROGRESS',
                          'prompt': text_prompt,
                          'num_samples': num_samples,
                          'calculate_fid': True,
                          'created_at': int(time.time()),
                          'expiration_time': expiration_time
                      }
                  )
                  
                  # Start asynchronous invocation of processor Lambda
                  lambda_client = boto3.client('lambda')
                  lambda_client.invoke(
                      FunctionName=os.environ.get('PROCESSOR_LAMBDA', ''),
                      InvocationType='Event',  # Asynchronous invocation
                      Payload=json.dumps({
                          'request_id': request_id,
                          'text_prompt': text_prompt,
                          'num_samples': num_samples,
                          'calculate_fid': True,
                          'endpoint_name': endpoint_name
                      })
                  )
                  
                  # Return the request ID to the client
                  return {
                      'statusCode': 200,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                      },
                      'body': json.dumps({
                          'request_id': request_id,
                          'status': 'IN_PROGRESS',
                          'message': 'Image generation with metrics started. Poll for results using the request_id.'
                      })
                  }
              except Exception as e:
                  return {
                      'statusCode': 500,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,POST,GET'
                      },
                      'body': json.dumps({
                          'error': str(e)
                      })
                  }
      Environment:
        Variables:
          ENVIRONMENT: !Ref EnvironmentName
          PROJECT_NAME: !Ref ProjectName
          SAGEMAKER_ENDPOINT_NAME: 'gan-ep-dev'
          DYNAMODB_TABLE: 'gan-text-to-image-dev-generation-jobs'
          PROCESSOR_LAMBDA: !GetAtt ProcessorLambda.Arn

  MetricsLambda:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: !Sub '${ProjectName}-${EnvironmentName}-metrics'
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.handler
      Timeout: 60
      MemorySize: 256
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import logging

          # Configure logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          
          # Constants for the specific training job
          TRAINING_JOB_NAME = "gan-train-2504270134"
          MODEL_ARTIFACTS_PATH = "s3://gan-text-to-image-dev-artifacts-207567761455/training/gan-train-2504270134/gan-train-2504270134/output/"
          
          def handler(event, context):
              # Log the incoming request
              logger.info(f"MetricsLambda received request: {json.dumps(event, default=str)}")
              
              # Initialize S3 client
              s3 = boto3.client('s3')
              
              try:
                  # Log that we're using the specific training job
                  logger.info(f"Using specific training job: {TRAINING_JOB_NAME}")
                  logger.info(f"Model artifacts path: {MODEL_ARTIFACTS_PATH}")
                  
                  # Extract bucket and path from the model artifacts path
                  bucket = MODEL_ARTIFACTS_PATH.split('/')[2]
                  model_dir = '/'.join(MODEL_ARTIFACTS_PATH.split('/')[3:])
                  
                  # Get metrics file - construct the full path
                  metrics_key = f"{model_dir}model_metrics.json"
                  logger.info(f"Looking for metrics file at s3://{bucket}/{metrics_key}")
                  
                  try:
                      response = s3.get_object(
                          Bucket=bucket,
                          Key=metrics_key
                      )
                      
                      metrics = json.loads(response['Body'].read().decode('utf-8'))
                      logger.info(f"Successfully retrieved metrics: {json.dumps(metrics, default=str)[:200]}...")
                      
                      return {
                          'statusCode': 200,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,GET,POST'
                          },
                          'body': json.dumps(metrics)
                      }
                  except s3.exceptions.NoSuchKey:
                      # Try with a different path pattern
                      metrics_key = f"{model_dir}/model_metrics.json"
                      logger.info(f"First path not found. Trying alternate path: s3://{bucket}/{metrics_key}")
                      
                      response = s3.get_object(
                          Bucket=bucket,
                          Key=metrics_key
                      )
                      
                      metrics = json.loads(response['Body'].read().decode('utf-8'))
                      logger.info(f"Successfully retrieved metrics from alternate path: {json.dumps(metrics, default=str)[:200]}...")
                      
                      return {
                          'statusCode': 200,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,GET,POST'
                          },
                          'body': json.dumps(metrics)
                      }
                  
              except Exception as e:
                  logger.error(f"Error retrieving metrics: {str(e)}")
                  return {
                      'statusCode': 500,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,GET,POST'
                      },
                      'body': json.dumps({
                          'error': str(e),
                          'message': 'Failed to retrieve model metrics'
                      })
                  }
      Environment:
        Variables:
          PROJECT_NAME: !Ref ProjectName
          ENVIRONMENT: !Ref EnvironmentName


  PollLambda:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: !Sub '${ProjectName}-${EnvironmentName}-poll'
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.handler
      Timeout: 750
      MemorySize: 256  # Reduced to 128MB to save costs
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          
          # Initialize DynamoDB client
          dynamodb = boto3.resource('dynamodb')
          
          def handler(event, context):
              # Get the table name from environment variables
              table_name = os.environ.get('DYNAMODB_TABLE', '')
              
              # Get the request_id from query parameters
              try:
                  request_id = event.get('queryStringParameters', {}).get('request_id', '')
                  
                  if not request_id:
                      return {
                          'statusCode': 400,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,GET,POST'
                          },
                          'body': json.dumps({
                              'error': 'request_id is required'
                          })
                      }
                  
                  # Get the job status from DynamoDB
                  table = dynamodb.Table(table_name)
                  response = table.get_item(Key={'request_id': request_id})
                  
                  # Check if the item exists
                  if 'Item' not in response:
                      return {
                          'statusCode': 404,
                          'headers': {
                              'Content-Type': 'application/json',
                              'Access-Control-Allow-Origin': '*',
                              'Access-Control-Allow-Headers': 'Content-Type',
                              'Access-Control-Allow-Methods': 'OPTIONS,GET,POST'
                          },
                          'body': json.dumps({
                              'error': 'Job not found'
                          })
                      }
                  
                  # Get the job item
                  job = response['Item']
                  
                  # Return the job status
                  return {
                      'statusCode': 200,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,GET,POST'
                      },
                      'body': json.dumps({
                          'status': job.get('status', 'UNKNOWN'),
                          'data': job.get('data', {})
                      })
                  }
              except Exception as e:
                  return {
                      'statusCode': 500,
                      'headers': {
                          'Content-Type': 'application/json',
                          'Access-Control-Allow-Origin': '*',
                          'Access-Control-Allow-Headers': 'Content-Type',
                          'Access-Control-Allow-Methods': 'OPTIONS,GET,POST'
                      },
                      'body': json.dumps({
                          'error': str(e)
                      })
                  }
      Environment:
        Variables:
          DYNAMODB_TABLE: 'gan-text-to-image-dev-generation-jobs'

  # ===== API Gateway =====
  APIGatewayRestAPI:
    Type: 'AWS::ApiGateway::RestApi'
    Properties:
      Name: !Sub '${ProjectName}-${EnvironmentName}-api'
      Description: 'API for the Text-to-Image GAN project'

  InferenceResource:
    Type: 'AWS::ApiGateway::Resource'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ParentId: !GetAtt APIGatewayRestAPI.RootResourceId
      PathPart: 'generate'

  ImageMetricsResource:
    Type: 'AWS::ApiGateway::Resource'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ParentId: !GetAtt APIGatewayRestAPI.RootResourceId
      PathPart: 'image-metrics'

  MetricsResource:
    Type: 'AWS::ApiGateway::Resource'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ParentId: !GetAtt APIGatewayRestAPI.RootResourceId
      PathPart: 'metrics'

  PollResource:
    Type: 'AWS::ApiGateway::Resource'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ParentId: !GetAtt APIGatewayRestAPI.RootResourceId
      PathPart: 'poll'

  InferenceMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref InferenceResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${InferenceLambda.Arn}/invocations'

  ImageMetricsMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref ImageMetricsResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${ImageMetricsLambda.Arn}/invocations'

  MetricsMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref MetricsResource
      HttpMethod: GET
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${MetricsLambda.Arn}/invocations'

  PollMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref PollResource
      HttpMethod: GET
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${PollLambda.Arn}/invocations'

  # ===== CORS Configuration =====
  # OPTIONS Method for the /generate endpoint
  InferenceOptionsMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref InferenceResource
      HttpMethod: OPTIONS
      AuthorizationType: NONE
      Integration:
        Type: MOCK
        IntegrationResponses:
          - StatusCode: 200
            ResponseParameters:
              'method.response.header.Access-Control-Allow-Headers': "'Content-Type'"
              'method.response.header.Access-Control-Allow-Methods': "'OPTIONS,POST'"
              'method.response.header.Access-Control-Allow-Origin': "'*'"
        RequestTemplates:
          'application/json': '{"statusCode": 200}'
      MethodResponses:
        - StatusCode: 200
          ResponseParameters:
            'method.response.header.Access-Control-Allow-Headers': true
            'method.response.header.Access-Control-Allow-Methods': true
            'method.response.header.Access-Control-Allow-Origin': true

  # OPTIONS Method for the /poll endpoint
  PollOptionsMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref PollResource
      HttpMethod: OPTIONS
      AuthorizationType: NONE
      Integration:
        Type: MOCK
        IntegrationResponses:
          - StatusCode: 200
            ResponseParameters:
              'method.response.header.Access-Control-Allow-Headers': "'Content-Type'"
              'method.response.header.Access-Control-Allow-Methods': "'OPTIONS,GET'"
              'method.response.header.Access-Control-Allow-Origin': "'*'"
        RequestTemplates:
          'application/json': '{"statusCode": 200}'
      MethodResponses:
        - StatusCode: 200
          ResponseParameters:
            'method.response.header.Access-Control-Allow-Headers': true
            'method.response.header.Access-Control-Allow-Methods': true
            'method.response.header.Access-Control-Allow-Origin': true

  # OPTIONS Method for the /metrics endpoint
  MetricsOptionsMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref MetricsResource
      HttpMethod: OPTIONS
      AuthorizationType: NONE
      Integration:
        Type: MOCK
        IntegrationResponses:
          - StatusCode: 200
            ResponseParameters:
              'method.response.header.Access-Control-Allow-Headers': "'Content-Type'"
              'method.response.header.Access-Control-Allow-Methods': "'OPTIONS,GET'"
              'method.response.header.Access-Control-Allow-Origin': "'*'"
        RequestTemplates:
          'application/json': '{"statusCode": 200}'
      MethodResponses:
        - StatusCode: 200
          ResponseParameters:
            'method.response.header.Access-Control-Allow-Headers': true
            'method.response.header.Access-Control-Allow-Methods': true
            'method.response.header.Access-Control-Allow-Origin': true

  # OPTIONS Method for the /image-metrics endpoint
  ImageMetricsOptionsMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      ResourceId: !Ref ImageMetricsResource
      HttpMethod: OPTIONS
      AuthorizationType: NONE
      Integration:
        Type: MOCK
        IntegrationResponses:
          - StatusCode: 200
            ResponseParameters:
              'method.response.header.Access-Control-Allow-Headers': "'Content-Type'"
              'method.response.header.Access-Control-Allow-Methods': "'OPTIONS,POST'"
              'method.response.header.Access-Control-Allow-Origin': "'*'"
        RequestTemplates:
          'application/json': '{"statusCode": 200}'
      MethodResponses:
        - StatusCode: 200
          ResponseParameters:
            'method.response.header.Access-Control-Allow-Headers': true
            'method.response.header.Access-Control-Allow-Methods': true
            'method.response.header.Access-Control-Allow-Origin': true


  # ===== Lambda Permissions =====
  InferenceLambdaPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref InferenceLambda
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${APIGatewayRestAPI}/*/POST/generate'

  ImageMetricsLambdaPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref ImageMetricsLambda
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${APIGatewayRestAPI}/*/POST/image-metrics'

  MetricsLambdaPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref MetricsLambda
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${APIGatewayRestAPI}/*/GET/metrics'

  PollLambdaPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref PollLambda
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${APIGatewayRestAPI}/*/GET/poll'

  APIGatewayDeployment:
    Type: 'AWS::ApiGateway::Deployment'
    DependsOn:
      - InferenceMethod
      - MetricsMethod
      - ImageMetricsMethod
      - PollMethod
      - InferenceOptionsMethod
      - MetricsOptionsMethod
      - ImageMetricsOptionsMethod
      - PollOptionsMethod
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      Description: 'Initial deployment with async support and CORS'

  APIGatewayStage:
    Type: 'AWS::ApiGateway::Stage'
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      StageName: v1
      DeploymentId: !Ref APIGatewayDeployment

  # ===== CloudWatch Dashboard =====
  MonitoringDashboard:
    Type: 'AWS::CloudWatch::Dashboard'
    Properties:
      DashboardName: !Sub '${ProjectName}-${EnvironmentName}-dashboard'
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/ApiGateway", "Count", "ApiName", "${ProjectName}-${EnvironmentName}-api" ]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "${AWS::Region}",
                "title": "API Gateway Request Count"
              }
            },
            {
              "type": "metric",
              "x": 12,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/Lambda", "Invocations", "FunctionName", "${ProjectName}-${EnvironmentName}-inference" ],
                  [ "AWS/Lambda", "Invocations", "FunctionName", "${ProjectName}-${EnvironmentName}-metrics" ],
                  [ "AWS/Lambda", "Invocations", "FunctionName", "${ProjectName}-${EnvironmentName}-poll" ]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "${AWS::Region}",
                "title": "Lambda Invocations"
              }
            },
            {
              "type": "metric",
              "x": 0,
              "y": 6,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  [ "AWS/Lambda", "Duration", "FunctionName", "${ProjectName}-${EnvironmentName}-inference" ],
                  [ "AWS/Lambda", "Duration", "FunctionName", "${ProjectName}-${EnvironmentName}-metrics" ],
                  [ "AWS/Lambda", "Duration", "FunctionName", "${ProjectName}-${EnvironmentName}-poll" ]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "Lambda Duration"
              }
            }
          ]
        }

Conditions:
  HasModelArtifact: !And [!Not [!Equals [!Ref ModelArtifactUrl, '']], !Not [!Equals [!Ref ContainerImage, '']]]

Outputs:
  SageMakerRoleArn:
    Description: "ARN of the SageMaker execution role"
    Value: !GetAtt SageMakerRole.Arn
    Export:
      Name: !Sub "${ProjectName}-${EnvironmentName}-sagemaker-role-arn"
  
  LambdaRoleArn:
    Description: "ARN of the Lambda execution role"
    Value: !GetAtt LambdaRole.Arn
    Export:
      Name: !Sub "${ProjectName}-${EnvironmentName}-lambda-role-arn"
  
  ModelArtifactBucketName:
    Description: "Name of the S3 bucket for model artifacts"
    Value: !Ref ModelArtifactBucket
    Export:
      Name: !Sub "${ProjectName}-${EnvironmentName}-model-artifact-bucket"
  
  APIEndpoint:
    Description: "URL of the API Gateway endpoint"
    Value: !Sub "https://${APIGatewayRestAPI}.execute-api.${AWS::Region}.amazonaws.com/v1"
    Export:
      Name: !Sub "${ProjectName}-${EnvironmentName}-api-endpoint"